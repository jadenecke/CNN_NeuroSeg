import numpy as np
import pyminc.volumes.factory as pyminc
import random
from random import randint
import os
import subprocess
from scipy import ndimage

def chunkify(lst,n):
        return [lst[i::n] for i in xrange(n)];

def read_text_as_list(text_file):
    with open(text_file) as f: text_list = f.read().splitlines(); text_list = np.array(text_list) 
    return text_list

def extract_patch(vol,patch_center,patch_radius):

        ### for dealing with multiple modalities, we return an N.W.W.W patch where N is # of modalities
  
        num_modalities = np.size(vol,0)
        patch = np.zeros([num_modalities,2*patch_radius+1,2*patch_radius+1,2*patch_radius+1])
        for i in range(0,num_modalities):
	    patch[i,:,:,:] = vol[i,patch_center[0]-patch_radius:patch_center[0]+patch_radius+1,patch_center[1]-patch_radius:patch_center[1]+patch_radius+1,patch_center[2]-patch_radius:patch_center[2]+patch_radius+1]        
            
        return patch
	
def extract_value(vol,position):
	value = vol[position[0],position[1],position[2]];
	return value

def read_minc_image(minc_filename):

        ### this will read in multiple modalities into an N.X.Y.Z volume where N is # of modalities

        split = minc_filename.split(',')
        minc_vol = pyminc.volumeFromFile(split[0]);
        vol = minc_vol.data;
        vol = np.expand_dims(vol,axis=0)

        if (np.size(split) > 1):
            for i in range(1,np.size(split)):
                minc_vol = pyminc.volumeFromFile(split[i]);
                vol = np.concatenate((vol,np.expand_dims(minc_vol.data,axis=0)),axis=0)
        
	return vol

def read_minc_label(minc_filename):
	minc_vol = pyminc.volumeFromFile(minc_filename, labels=True);
	vol = np.copy(minc_vol.data);
	minc_vol.closeVolume()
	return vol

def pad_volume(vol,pad_value):
	vol = np.pad(vol, [(0,0),(pad_value,pad_value),(pad_value,pad_value),(pad_value,pad_value)],'constant',constant_values=0)
	return vol

def unpad_volume(vol,pad_value):
	vol = vol[pad_value:-pad_value,pad_value:-pad_value,pad_value:-pad_value]
	return vol    

def get_random_coords(mask,number_of_indices):
	array_of_coords = np.transpose(np.nonzero(mask))
	rc = random.sample(array_of_coords,number_of_indices)
	return rc

def standardize(patch,eps):
    
    for i in range(0,np.size(patch,0)):
        patch[i,:,:,:] = (patch[i,:,:,:] - np.mean(patch[i,:,:,:])) / (np.std(patch[i,:,:,:]) + eps)
    return patch  

def get_training_data_ima(image,mask,posterior,location_ima,array_of_coords,input_patch_radius,output_patch_radius):  

    input_patch_width = 2*input_patch_radius + 1
    output_patch_width = 2*output_patch_radius + 1

    num_modalities = np.size(image,0)

    # make arrays
    x_train = np.zeros([np.size(array_of_coords,0),num_modalities,input_patch_width,input_patch_width,input_patch_width])
    p_train = np.zeros([np.size(array_of_coords,0),1,input_patch_width,input_patch_width,input_patch_width])
    y_train = np.zeros([np.size(array_of_coords,0),1,output_patch_width,output_patch_width,output_patch_width])
    l_train = np.zeros([np.size(array_of_coords,0),3,input_patch_width,input_patch_width,input_patch_width])

    # extract features
    for n in range(0,np.size(array_of_coords,0)):

        patch = extract_patch(image,array_of_coords[n],input_patch_radius); patch = standardize(patch,0.0001)
        patch_pos = extract_patch(posterior,array_of_coords[n],input_patch_radius)
        patch_loc = extract_patch(location_ima,array_of_coords[n],input_patch_radius)
        true = extract_patch(mask,array_of_coords[n],output_patch_radius)
        
        x_train[n,:,:,:,:] = patch
        p_train[n,:,:,:,:] = patch_pos
        l_train[n,:,:,:,:] = patch_loc
    	y_train[n,:,:,:,:] = true

    return (x_train, p_train, l_train, y_train)


def get_coords_stride(array_of_coords,stride):
 
    for i in range(np.size(array_of_coords,0)-1,-1,-1):
        print i
        if (array_of_coords[i][0] % stride != 0):
            array_of_coords = np.delete(array_of_coords,i,axis=0)

    for i in range(np.size(array_of_coords,0)-1,-1,-1):
        print i
        if (array_of_coords[i][1] % stride != 0):
            array_of_coords = np.delete(array_of_coords,i,axis=0)

    for i in range(np.size(array_of_coords,0)-1,-1,-1):
        print i
        if (array_of_coords[i][2] % stride != 0):
            array_of_coords = np.delete(array_of_coords,i,axis=0)

    return array_of_coords    

def get_training_data(image_list,mask_list,posterior_list,sampling_masks,max_patches_per_image,uniform_sampling,input_patch_radius,output_patch_radius):
    
    eps = 0.0001
    image = read_minc_image(image_list[0]); image = pad_volume(image,input_patch_radius)
    location_ima = make_location_ima(np.squeeze(image[0,:,:,:])); 
    label_mask = read_minc_image(mask_list[0]);
    num_labels = np.amax(label_mask) + 1

    for subj in range(0,np.size(image_list)):

        image = read_minc_image(image_list[subj]); image = pad_volume(image,input_patch_radius)
        mask = read_minc_image(mask_list[subj]); mask = pad_volume(mask,input_patch_radius)
        posterior = read_minc_image(posterior_list[subj]); posterior = pad_volume(posterior,input_patch_radius)
        sampling_mask = read_minc_image(sampling_masks[subj]); sampling_mask = pad_volume(sampling_mask,input_patch_radius)
        
        if (uniform_sampling == 1):
            array_of_coords = np.transpose(np.nonzero(np.squeeze(sampling_mask)))
            array_of_coords = random.sample(array_of_coords,max_patches_per_image)
  
        if (uniform_sampling == 0):
            for label in range(0,num_labels):
                label_mask = mask; label_mask[label_mask < label] = 0; label_mask[label_mask > label] = 0;
                array_of_coords_label = np.transpose(np.nonzero(np.multiply(np.squeeze(sampling_mask),np.squeeze(label_mask))))
                array_of_coords_label = random.sample(array_of_coords_label,np.round(max_patches_per_image/num_labels))
                print np.size(array_of_coords_label)

                if label == 0:
                    array_of_coords = array_of_coords_label
                else:
                    array_of_coords = np.concatenate((array_of_coords,array_of_coords_label),axis=0)

        x_train_ima, p_train_ima, l_train_ima, y_train_ima = get_training_data_ima(image,mask,posterior,location_ima,array_of_coords,input_patch_radius,output_patch_radius) 
        
        if subj == 0:
            x_train = x_train_ima; 
            p_train = p_train_ima; 
            l_train = l_train_ima; 
            y_train = y_train_ima;
        else:
            x_train = np.concatenate((x_train,x_train_ima),axis=0); 
            p_train = np.concatenate((p_train,p_train_ima),axis=0); 
            l_train = np.concatenate((l_train,l_train_ima),axis=0); 
            y_train = np.concatenate((y_train,y_train_ima),axis=0); 

    # convert to float
    x_train = x_train.astype(np.float32); p_train = p_train.astype(np.float32); l_train = l_train.astype(np.float32); y_train = y_train.astype(np.int32)

    print "Extracted " + str(np.size(x_train,0)) + " patches."

    return (x_train, p_train, l_train, y_train)
        
 
def get_training_data_preloaded(images,masks,posteriors,sampling_masks,max_patches_per_image,uniform_sampling,input_patch_radius,output_patch_radius):

    eps = 0.0001
    location_ima = make_location_ima(np.squeeze(images[0,0,:,:,:]))
    num_labels = np.amax(masks[0,0,:,:,:]).astype(int) + 1

    for subj in range(0,np.size(images,0)):

        image = images[subj,:,:,:,:]
        mask = masks[subj,:,:,:,:]
        posterior = posteriors[subj,:,:,:,:]
        sampling_mask = sampling_masks[subj,:,:,:,:]

        if (uniform_sampling == 1):
            array_of_coords = np.transpose(np.nonzero(np.squeeze(sampling_mask)))
            array_of_coords = random.sample(array_of_coords,max_patches_per_image)
  
        if (uniform_sampling == 0):
            for label in range(0,num_labels):
                label_mask = np.zeros(np.shape(mask)); label_mask[mask == label] = 1;
                array_of_coords_label = np.transpose(np.nonzero(np.multiply(np.squeeze(sampling_mask),np.squeeze(label_mask))))
                array_of_coords_label = random.sample(array_of_coords_label,np.round(max_patches_per_image/num_labels).astype(int))

                if label == 0:
                    array_of_coords = array_of_coords_label
                else:
                    array_of_coords = np.concatenate((array_of_coords,array_of_coords_label),axis=0)

        x_train_ima, p_train_ima, l_train_ima, y_train_ima = get_training_data_ima(image,mask,posterior,location_ima,array_of_coords,input_patch_radius,output_patch_radius) 
        
        if subj == 0:
            x_train = x_train_ima; 
            p_train = p_train_ima; 
            l_train = l_train_ima; 
            y_train = y_train_ima;
        else:
            x_train = np.concatenate((x_train,x_train_ima),axis=0); 
            p_train = np.concatenate((p_train,p_train_ima),axis=0); 
            l_train = np.concatenate((l_train,l_train_ima),axis=0); 
            y_train = np.concatenate((y_train,y_train_ima),axis=0); 


    # convert to float
    x_train = x_train.astype(np.float32); p_train = p_train.astype(np.float32); l_train = l_train.astype(np.float32); y_train = y_train.astype(np.int32)

    print "Extracted " + str(np.size(x_train,0)) + " patches."

    return (x_train, p_train, l_train, y_train)

def read_list_into_array(list):

    array = read_minc_image(list[0]); array = np.expand_dims(array,axis=0)
    for n in range(1,np.size(list)):
        d = read_minc_image(list[n]); d = np.expand_dims(d,axis=0); array = np.concatenate((array,d),axis=0)

    return array

def read_lists_into_arrays(image_list,posterior_list,mask_list,sampling_mask_list):

    images = read_list_into_array(image_list)
    posteriors = read_list_into_array(posterior_list)
    masks = read_list_into_array(mask_list)
    sampling_masks = read_list_into_array(sampling_mask_list)

    return images, posteriors, sampling_masks, masks

def pad_arrays(images,posteriors,masks,sampling_masks,pad_value):
 
    images = np.pad(images, ((0,0),(0,0),(pad_value,pad_value),(pad_value,pad_value),(pad_value,pad_value)),'constant',constant_values=0)
    posteriors = np.pad(posteriors, ((0,0),(0,0),(pad_value,pad_value),(pad_value,pad_value),(pad_value,pad_value)),'constant',constant_values=0)
    masks = np.pad(masks, ((0,0),(0,0),(pad_value,pad_value),(pad_value,pad_value),(pad_value,pad_value)),'constant',constant_values=0)
    sampling_masks = np.pad(sampling_masks, ((0,0),(0,0),(pad_value,pad_value),(pad_value,pad_value),(pad_value,pad_value)),'constant',constant_values=0)

    return images, posteriors, sampling_masks, masks

def make_location_ima(image):

    x_image = np.zeros(np.shape(image))
    for d in range(0,np.size(image,0)):
        x_image[d,:,:] = (d+1)*np.ones([np.size(image,1),np.size(image,2)])
    x_image = np.expand_dims(x_image,axis=0)
    x_image = x_image / np.max(x_image)    

    y_image = np.zeros(np.shape(image))
    for d in range(0,np.size(image,1)):
        y_image[:,d,:] = (d+1)*np.ones([np.size(image,0),np.size(image,2)])
    y_image = np.expand_dims(y_image,axis=0) 
    y_image = y_image / np.max(y_image)

    z_image = np.zeros(np.shape(image))
    for d in range(0,np.size(image,2)):
        z_image[:,:,d] = (d+1)*np.ones([np.size(image,0),np.size(image,1)])    
    z_image = np.expand_dims(z_image,axis=0) 
    z_image = z_image / np.max(z_image)

    location_ima = np.concatenate((x_image,y_image,z_image),axis=0)

    return location_ima

def get_sm_from_pos(posteriors,sampling_radius):

    sampling_masks = np.zeros(np.shape(posteriors))

    for i in range(0,np.size(posteriors,0)):
        dilated = ndimage.binary_dilation(np.squeeze(posteriors[i,0,:,:,:]), structure=np.ones((2*sampling_radius+1,2*sampling_radius+1,2*sampling_radius+1))).astype(posteriors.dtype)
        eroded = ndimage.binary_erosion(np.squeeze(posteriors[i,0,:,:,:]), structure=np.ones((2*sampling_radius+1,2*sampling_radius+1,2*sampling_radius+1))).astype(posteriors.dtype)
        sampling_masks[i,0,:,:,:] = dilated - eroded
        #print np.sum(sampling_masks[i,0,:,:,:])

    return sampling_masks

def get_spm_from_masks(masks):

    spm = np.mean(masks,axis=0)

    return spm

def write_minc_image(array,example_image_filename,output_name):

    in_vol = pyminc.volumeFromFile(example_image_filename)

    out_vol = pyminc.volumeFromInstance(in_vol,output_name)
    out_vol.data = np.squeeze(array);
    out_vol.writeFile()

    in_vol.closeVolume()
    out_vol.closeVolume()

def augment_patches(x_train,p_train,l_train,y_train):

    inds = np.arange(np.size(x_train,0)).astype(np.int32)
    #rot_axes = [(2,3),(3,4),(2,4)]
    chunked = chunkify(inds,4)

    for d in range(3):
        x_train[chunked[d],:,:,:,:] = np.flip(x_train[chunked[d],:,:,:,:],d+2)
     	p_train[chunked[d],:,:,:,:] = np.flip(p_train[chunked[d],:,:,:,:],d+2)
     	l_train[chunked[d],:,:,:,:] = np.flip(l_train[chunked[d],:,:,:,:],d+2)
    	y_train[chunked[d],:,:,:,:] = np.flip(y_train[chunked[d],:,:,:,:],d+2)

    #for d in range(3):
    #    x_train[chunked[d+3],:,:,:,:] = np.rot90(x_train[chunked[d+3],:,:,:,:],k=2,axes=rot_axes[d])
    # 	p_train[chunked[d+3],:,:,:,:] = np.rot90(p_train[chunked[d+3],:,:,:,:],k=2,axes=rot_axes[d])
    # 	l_train[chunked[d+3],:,:,:,:] = np.rot90(l_train[chunked[d+3],:,:,:,:],k=2,axes=rot_axes[d])
    # 	y_train[chunked[d+3],:,:,:,:] = np.rot90(y_train[chunked[d+3],:,:,:,:],k=2,axes=rot_axes[d])

    return x_train, p_train, l_train, y_train

    

